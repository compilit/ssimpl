{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"1. SSIMPL - Specification The SSIMPL protocol described in the following specification addresses a few problems that have existed since the early days of the internet \u2014 certainly since Web 2.0: How do you keep the owner of the online identity in control of their identity data? There have been several iterations of OAuth in the past, one of which (Open ID Connect), was meant to add an identification layer to a protocol that's otherwise solely used for delegated authorization. This identity layer, however, has never been implemented in a way that anyone can truly rely on. It requires a certain amount of trust, which is provided in the form of billion-dollar companies saying \"this data belongs to the person who just logged in\". But it adds no guarantees about the validity of those claims. In order to minimize the amount of trust necessary for identification, it is essential that individuals are capable of managing their digital identity themselves, this is known as SSI - Self-Sovereign-Identity . But a self-issued identity still isn't worth much if it is not verified. How do you verify someone\u2019s digital identity? Online, everyone can claim to anyone. For some systems - like social media - that could be fine. But for professional services, it is of the utmost importance that all parties taking part in any kind of transaction, have a verified identity shared among the other participants. This issue has become even more critical with the rise of AI and bots capable of impersonating individuals with minimal effort. SSIMPL stands for Self-Sovereign Identity & Mondial Pseudonymous Ledger. Which tells us already quite a bit about its components. SSIMPL tries to find a balance between centralised and decentralised systems. It creates a bridge between the physical and digital worlds through authority-backed cryptographic proof. Therefor, implementing SSIMPL requires a trusted central authority (such as a government) that supports some form of one-time, cryptography-based identification for individuals. 1.1 Means of identification Online identities are usually based upon a certain amount of trust. In it's worst form this trust is based on the user filling in their own identity-details in an open form. At its best, it's based on some authority having determined you are who you say you are. By scanning your passport for example. In order to establish a truly trustworthy online identity, we must somehow match an actual person to some digital claims. All this is done in the wallet itself. But to be able to achieve that, there is one requirement: All users of the SSIMPL protocol MUST possess a Standardised e-passport . 1.2 The wallet The wallet is the core component that holds the owners most important data: their 'claims' and the means to support those claims. A wallet can be defined as a secure means to store digital data that can only be accessed by its owner. In the spirit of Open ID Connect, the wallet gives a user all the components needed to authenticate themselves online at multiple levels: Level 0: The DID belongs to a human being. Level 1: Level 0 + unverified claims attached to the DID (requested via scope). Level 2: Level 1 + verified claims attached to the DID (requested via scope). Level 0 is sufficient to prove the user is not an AI or bot. Level 1 may be used when specific, unverified attributes are needed, like an address or a phone number. Level 2 provides verified claims. The requestor of these claims merely needs to request a certain scope of claims. You, as the owner then needs to approve this request and send them the requested claims, while signing them with your wallet. At the same time, the user will have the ability to cryptographically sign anything they would want to be associated with. In other words: if they would like to be able to proof they were the original creator of some digital content, all they would need to do is sign it. Other people could sign it as well, of course, but signature cannot be created using a past date. So the first one to sign something, always can proof they were the original creator. The wallet MUST perform an Active-Authentication challenge . The wallet SHOULD store the DG11, which contains the personal details of the owner which can be the first basic, verified claims. The wallet MUST be a decentralised BIP32-compliant implementation. The wallet MUST be backed-up up with a BIP39-compliant mnemonic phrase (stored offline). The wallet MUST be able to store both a root keypair that can be used to sign and verify data and to authorize the bearer online, and all claims of the owner. The root public key MUST be used to generate a DID (decentralised Identifier), which is then signed by the neutral third party. All encoded data, like the cryptographic keys, MUST be encoded using Multibase-encoding to ensure all peers of all possible future implementations always know which encoding is used. The wallet MUST have one or many associated online storages where the 'subscription' can be stored. The wallet MUST have the ability to encrypt claims and store them as a 'subscription' object on an online storage. The wallet MUST have the ability to generate a JWT (Authentication & UCAN). The wallet MUST be able to perform asymmetric encryption in order to share a (or establish a mutual) secret. 1.3 Mondial Pseudonymous Ledger In order to protect users from misuse, fraud and identity-theft, each wallet (and specifically the related public keys), must have a mechanism that allows them to be invalidated. These invalidated public keys must be published to a publicly accessible, append-only, preferably decentralized, data storage. Anytime someone suspects their identity has been compromised, they're required to add their public keys to the ledger. This way, everyone can check whether the identity they're dealing with is actually valid. The ledger also contains the public keys of so-called \"neutral ledger authorities\" (similar to a notary). Each entity that is allowed to sign newly created DIDs. This signature serves as proof that the owner of the DID successfully has authenticated themselves using their e-passport. The ledger MUST contain an append-only list for all its invalidated entries. The ledger SHOULD contain a list of DID's that are 'designated SSIMPL authorities', meaning they can sign initial DID's. The ledger SHOULD allow updates on the 'designated SSIMPL authorities' list by the owners of the DID's, proven by providing a signed version of the DID. The ledger SHOULD be decentralised. 1.4 Subscriptions The ability to establish a verified, digital identity is only part of the equation of an id-wallet. It is essential that parts of this identity can be shared with other entities on the internet. A simple example would be 'signing in' on a website. Originally these parts of your identity (aka 'Claims'), come from a centralised service which has your profile stored. SSIMPL offers a completely new perspective. Since you already have the claims stored in your own wallet, there is no need for an external, centralised service. Instead, the entity interested in your claims shares with you the necessary claims ( aka a ' Scope') to sign in or complete some transaction, a webhook to provide the entity with the web-location of the ( temporary) subscription on those claims, and, finally, the UCAN token necessary to access that web-locations' endpoint. This 'subscription' is called that, because the duration that the endpoint is reserved could potentially last longer than just one transaction. Meaning that you could update the claims if necessary and the other party could fetch the new data once again. By default, the endpoint is random and must 'self-destruct'. Meaning that neither the owner of the data nor the other party can interact with it anymore. Each online storage MUST delete the subscription after being read once. Each storage endpoint MUST send a 200 OK with the subscription the first time it's accessed, and a 204 NO CONTENT ( without content...) for the duration of the subscription or until the subscription is updated again. Each storage endpoint path must remain reserved for the duration of the subscription. Each storage endpoint MUST allow updates by the owner for the duration of the subscription. 1.4.1 Example: Authentication With SSIMPL, using a third party to provide another party with your identity data has become obsolete. But how DO we share our claims with something like a webshop? Let's set up a scenario. We start with these parties: Party A. The owner of the identity with their id-wallet. Party B. A website (front- and backend), let's say a webshop called \"foo-bar.baz\". Party C. The online storage used for the (temporary) storage of the 'subscription'. Pre-requisite: all parties have a DID, signed by a neutral ' notary ' server. For a non-natural person, this means a DID from someone inside the legal entity, willing to represent the legal entity. Party A visits Party B, which at some point requires A to identify themselves (to complete an order, for example) Party B has to create a scannable image (like a QR-code), which provides Party B all necessary information to authenticate Party A Party A uses their wallet to scan the image The wallet of Party A verifies the contents of the payload and shows it to Party A Party A verifies and accepts the request The wallet gathers the necessary claims, combines them into a 'subscription' object, encrypts it, and stores it at Party C Party C reserves the web-location for the duration of the subscription Party C responds with the web-location of this subscription The wallet of Party A then creates a UCAN token which grants Party B one-time access to this the specific web-location The wallet of Party A sends this token to the destination defined in the original request Party B uses the token to retrieve the subscription Party C deletes the data 1.4.2 Subscription request payload { \"audience\": \"<did:of:partyB>\", \"scopes\": [ \"did\", \"private-address\" ], \"destination\": \"https://some.endpoint/webhook\" } 1.5 Security In order to fully implement SSI, a user needs to have full control over their own data. There are several ways to accomplish this (using a hardware wallet for example), but SSIMPL relies on a somewhat controversial take: most people have a smartphone and treat it with more respect than their passport. Smartphones these days lack true HSMs (Hardware Security Modules), which would be the best place for cryptographic material to exist. Due to this (hopefully temporary) imperfection in smartphones, SSIMPL requires you to use the keystores that exist on devices: Keychain on iOS and the KeyStore on Android. This introduces a few risks that need to be mitigated: The device is lost/stolen, the related wallet needs to be invalidated. - This is achieved by registering the DID on a decentralised ledger. It would require you use the mnemonic phrase on a new device to re-create your wallet, then invalidate it. The user can then create a new wallet again. A user switches devices, the wallet needs to be re-created. - The mnemonic phrase can be used to re-create the old wallet. Always do take care to either delete the wallet from the device, or to factory-reset the device. The mnemonic phrase is lost/stolen. - The user will need to invalidate their current DID and create a new wallet (which will also mean the user gets a new mnemonic phrase) A user loses both their mnemonic phrase and their phone. - This scenario should be prevented at all costs, since everything relies on that mnemonic phrase. And no mitigation exists for this scenario. It is advised to use a ( maybe even redundant) paper/metal backup to keep the mnemonic phrase safe.","title":"Home"},{"location":"#1-ssimpl-specification","text":"The SSIMPL protocol described in the following specification addresses a few problems that have existed since the early days of the internet \u2014 certainly since Web 2.0: How do you keep the owner of the online identity in control of their identity data? There have been several iterations of OAuth in the past, one of which (Open ID Connect), was meant to add an identification layer to a protocol that's otherwise solely used for delegated authorization. This identity layer, however, has never been implemented in a way that anyone can truly rely on. It requires a certain amount of trust, which is provided in the form of billion-dollar companies saying \"this data belongs to the person who just logged in\". But it adds no guarantees about the validity of those claims. In order to minimize the amount of trust necessary for identification, it is essential that individuals are capable of managing their digital identity themselves, this is known as SSI - Self-Sovereign-Identity . But a self-issued identity still isn't worth much if it is not verified. How do you verify someone\u2019s digital identity? Online, everyone can claim to anyone. For some systems - like social media - that could be fine. But for professional services, it is of the utmost importance that all parties taking part in any kind of transaction, have a verified identity shared among the other participants. This issue has become even more critical with the rise of AI and bots capable of impersonating individuals with minimal effort. SSIMPL stands for Self-Sovereign Identity & Mondial Pseudonymous Ledger. Which tells us already quite a bit about its components. SSIMPL tries to find a balance between centralised and decentralised systems. It creates a bridge between the physical and digital worlds through authority-backed cryptographic proof. Therefor, implementing SSIMPL requires a trusted central authority (such as a government) that supports some form of one-time, cryptography-based identification for individuals.","title":"1. SSIMPL - Specification"},{"location":"#11-means-of-identification","text":"Online identities are usually based upon a certain amount of trust. In it's worst form this trust is based on the user filling in their own identity-details in an open form. At its best, it's based on some authority having determined you are who you say you are. By scanning your passport for example. In order to establish a truly trustworthy online identity, we must somehow match an actual person to some digital claims. All this is done in the wallet itself. But to be able to achieve that, there is one requirement: All users of the SSIMPL protocol MUST possess a Standardised e-passport .","title":"1.1 Means of identification"},{"location":"#12-the-wallet","text":"The wallet is the core component that holds the owners most important data: their 'claims' and the means to support those claims. A wallet can be defined as a secure means to store digital data that can only be accessed by its owner. In the spirit of Open ID Connect, the wallet gives a user all the components needed to authenticate themselves online at multiple levels: Level 0: The DID belongs to a human being. Level 1: Level 0 + unverified claims attached to the DID (requested via scope). Level 2: Level 1 + verified claims attached to the DID (requested via scope). Level 0 is sufficient to prove the user is not an AI or bot. Level 1 may be used when specific, unverified attributes are needed, like an address or a phone number. Level 2 provides verified claims. The requestor of these claims merely needs to request a certain scope of claims. You, as the owner then needs to approve this request and send them the requested claims, while signing them with your wallet. At the same time, the user will have the ability to cryptographically sign anything they would want to be associated with. In other words: if they would like to be able to proof they were the original creator of some digital content, all they would need to do is sign it. Other people could sign it as well, of course, but signature cannot be created using a past date. So the first one to sign something, always can proof they were the original creator. The wallet MUST perform an Active-Authentication challenge . The wallet SHOULD store the DG11, which contains the personal details of the owner which can be the first basic, verified claims. The wallet MUST be a decentralised BIP32-compliant implementation. The wallet MUST be backed-up up with a BIP39-compliant mnemonic phrase (stored offline). The wallet MUST be able to store both a root keypair that can be used to sign and verify data and to authorize the bearer online, and all claims of the owner. The root public key MUST be used to generate a DID (decentralised Identifier), which is then signed by the neutral third party. All encoded data, like the cryptographic keys, MUST be encoded using Multibase-encoding to ensure all peers of all possible future implementations always know which encoding is used. The wallet MUST have one or many associated online storages where the 'subscription' can be stored. The wallet MUST have the ability to encrypt claims and store them as a 'subscription' object on an online storage. The wallet MUST have the ability to generate a JWT (Authentication & UCAN). The wallet MUST be able to perform asymmetric encryption in order to share a (or establish a mutual) secret.","title":"1.2 The wallet"},{"location":"#13-mondial-pseudonymous-ledger","text":"In order to protect users from misuse, fraud and identity-theft, each wallet (and specifically the related public keys), must have a mechanism that allows them to be invalidated. These invalidated public keys must be published to a publicly accessible, append-only, preferably decentralized, data storage. Anytime someone suspects their identity has been compromised, they're required to add their public keys to the ledger. This way, everyone can check whether the identity they're dealing with is actually valid. The ledger also contains the public keys of so-called \"neutral ledger authorities\" (similar to a notary). Each entity that is allowed to sign newly created DIDs. This signature serves as proof that the owner of the DID successfully has authenticated themselves using their e-passport. The ledger MUST contain an append-only list for all its invalidated entries. The ledger SHOULD contain a list of DID's that are 'designated SSIMPL authorities', meaning they can sign initial DID's. The ledger SHOULD allow updates on the 'designated SSIMPL authorities' list by the owners of the DID's, proven by providing a signed version of the DID. The ledger SHOULD be decentralised.","title":"1.3 Mondial Pseudonymous Ledger"},{"location":"#14-subscriptions","text":"The ability to establish a verified, digital identity is only part of the equation of an id-wallet. It is essential that parts of this identity can be shared with other entities on the internet. A simple example would be 'signing in' on a website. Originally these parts of your identity (aka 'Claims'), come from a centralised service which has your profile stored. SSIMPL offers a completely new perspective. Since you already have the claims stored in your own wallet, there is no need for an external, centralised service. Instead, the entity interested in your claims shares with you the necessary claims ( aka a ' Scope') to sign in or complete some transaction, a webhook to provide the entity with the web-location of the ( temporary) subscription on those claims, and, finally, the UCAN token necessary to access that web-locations' endpoint. This 'subscription' is called that, because the duration that the endpoint is reserved could potentially last longer than just one transaction. Meaning that you could update the claims if necessary and the other party could fetch the new data once again. By default, the endpoint is random and must 'self-destruct'. Meaning that neither the owner of the data nor the other party can interact with it anymore. Each online storage MUST delete the subscription after being read once. Each storage endpoint MUST send a 200 OK with the subscription the first time it's accessed, and a 204 NO CONTENT ( without content...) for the duration of the subscription or until the subscription is updated again. Each storage endpoint path must remain reserved for the duration of the subscription. Each storage endpoint MUST allow updates by the owner for the duration of the subscription.","title":"1.4 Subscriptions"},{"location":"#141-example-authentication","text":"With SSIMPL, using a third party to provide another party with your identity data has become obsolete. But how DO we share our claims with something like a webshop? Let's set up a scenario. We start with these parties: Party A. The owner of the identity with their id-wallet. Party B. A website (front- and backend), let's say a webshop called \"foo-bar.baz\". Party C. The online storage used for the (temporary) storage of the 'subscription'. Pre-requisite: all parties have a DID, signed by a neutral ' notary ' server. For a non-natural person, this means a DID from someone inside the legal entity, willing to represent the legal entity. Party A visits Party B, which at some point requires A to identify themselves (to complete an order, for example) Party B has to create a scannable image (like a QR-code), which provides Party B all necessary information to authenticate Party A Party A uses their wallet to scan the image The wallet of Party A verifies the contents of the payload and shows it to Party A Party A verifies and accepts the request The wallet gathers the necessary claims, combines them into a 'subscription' object, encrypts it, and stores it at Party C Party C reserves the web-location for the duration of the subscription Party C responds with the web-location of this subscription The wallet of Party A then creates a UCAN token which grants Party B one-time access to this the specific web-location The wallet of Party A sends this token to the destination defined in the original request Party B uses the token to retrieve the subscription Party C deletes the data","title":"1.4.1 Example: Authentication"},{"location":"#142-subscription-request-payload","text":"{ \"audience\": \"<did:of:partyB>\", \"scopes\": [ \"did\", \"private-address\" ], \"destination\": \"https://some.endpoint/webhook\" }","title":"1.4.2 Subscription request payload"},{"location":"#15-security","text":"In order to fully implement SSI, a user needs to have full control over their own data. There are several ways to accomplish this (using a hardware wallet for example), but SSIMPL relies on a somewhat controversial take: most people have a smartphone and treat it with more respect than their passport. Smartphones these days lack true HSMs (Hardware Security Modules), which would be the best place for cryptographic material to exist. Due to this (hopefully temporary) imperfection in smartphones, SSIMPL requires you to use the keystores that exist on devices: Keychain on iOS and the KeyStore on Android. This introduces a few risks that need to be mitigated: The device is lost/stolen, the related wallet needs to be invalidated. - This is achieved by registering the DID on a decentralised ledger. It would require you use the mnemonic phrase on a new device to re-create your wallet, then invalidate it. The user can then create a new wallet again. A user switches devices, the wallet needs to be re-created. - The mnemonic phrase can be used to re-create the old wallet. Always do take care to either delete the wallet from the device, or to factory-reset the device. The mnemonic phrase is lost/stolen. - The user will need to invalidate their current DID and create a new wallet (which will also mean the user gets a new mnemonic phrase) A user loses both their mnemonic phrase and their phone. - This scenario should be prevented at all costs, since everything relies on that mnemonic phrase. And no mitigation exists for this scenario. It is advised to use a ( maybe even redundant) paper/metal backup to keep the mnemonic phrase safe.","title":"1.5 Security"},{"location":"concepts/","text":"Concepts 1. BIP BIP stands for Bitcoin Improvement Proposal \u2014 it\u2019s a formal design document used to propose changes or additions to Bitcoin\u2019s protocol, processes, or tools. It\u2019s essentially the \u201cRFC\u201d (Request for Comments) system for Bitcoin. Each BIP has: A number (e.g., BIP-39) A type (Standards Track, Informational, or Process) A status (Draft, Proposed, Final, etc.) A detailed specification of the proposed change. For example: BIP-32 defines hierarchical deterministic (HD) wallets. BIP-39 defines mnemonic phrases (seed words). BIP-44 defines a multi-account wallet structure. While SSIMPL has nothing to do with Bitcoin, or even blockchains, it does rely upon some of the same concepts. 1.1 BIP32 BIP32 (Bitcoin Improvement Proposal 32) defines Hierarchical Deterministic (HD) wallets, which allow you to derive a tree of key pairs from a single root seed. Key features: One backup = all keys: Backing up the seed gives access to all derived keys. Key separation: You can derive independent identities (child keys) without compromising the master. Public derivation: Given a parent public key, you can derive child public keys (but not private keys). Hardened derivation: A safer variant where child keys can\u2019t be derived from public keys, but requires the parent private key. How it works: You start with a single seed (often from a BIP39 mnemonic). From that seed, it deterministically derives a master keypair (private + public key). Then you can derive child key pairs from the master, and children of those, forming a tree structure. 1.2 BIP39 BIP39 (Bitcoin Improvement Proposal 39) defines a way to represent a deterministic wallet\u2019s private key using a human-readable set of words, called a mnemonic phrase. Key properties: Mnemonic = backup: If you lose your device, you can recover your entire wallet using the phrase. Language-agnostic: Wordlists exist for multiple languages. Deterministic: The same phrase will always regenerate the same wallet. How it works: First, a cryptographically strong random number (entropy) is generated. Then that number is converted into a sequence of 12\u201324 words chosen from a predefined list of 2048 words. Finally, this phrase can be used to derive a seed, which in turn can generate a hierarchy of keys (e.g., via BIP32). 2. Self-Sovereign-Identity Self-Sovereign Identity (SSI) is a Decentralised identity model where individuals control their own digital identities without relying on central authorities. The main issue which the concept SSI usually tends to ignore is 'truth'. As long an individual is in complete control of their own digital identity, who is to say this individual is not impersonating some other individual, or worse, conjuring up a completely new non-existing identity. Cryptography can verify who issued a claim and whether it was tampered with, but it cannot verify the truthfulness of the claim itself. The validity of claims like a name, nationality, or birthdate ultimately depends on who the issuer is and whether they are trusted. However, since this requires authorities to be fully aligned with Web3 standards, we hit a dead end. Currently, most (if not all) authorities don't have any way to issue a DID . So what SSIMPL does, is reversing the flow yet again: an individual can create their own DID along with the related cryptographic keys. Which is actually in line with the entire idea of decentralisation. But 'claims' an individual makes are divided into 2 categories: formal and informal. 2.1 Informal Claims Informal claims can be made within certain scopes, where the user provides their own data along with their signature. By nature, these claims cannot be verified by an authority. However, other identities can attest to a claim by signing it, effectively endorsing its validity. This attestation carries moral responsibility, as the signer\u2019s DID and signature become publicly associated with the claim. 2.2 Formal Claims Formal claims cannot be self-issued; they must come from a recognized authority. At this point in time, the only formal claims available to a SSIMPL user, are the ones coming from their passport. These can be used to chain other claims of course. For example: by taking your full name and birthdate, you can match then with the names and birthdate written on an official diploma. 3. DID Decentralised IDentifier. A DID is a globally unique identifier that is not controlled by a central authority. Unlike traditional identifiers (usernames, emails, etc.), a DID is linked to a cryptographic keypair, allowing users to prove ownership without relying on a centralised system. A DID follows this format: did:<method>:<identifier> In SSIMPL, primarily the 'key' method is used. This means that each 'identifier' part is actually the public part of a specific cryptographic public/private keypair. Each user is responsible for their own private key, which is used to sign data. The public key can always be used to verify the signature. The only small deviation from the spec is that SSIMPL promotes the use of Multibase encoding , which means that even the public key part of the DID is multibase-encoded. The 'key' method also means there is no real need for a DID document, which is part of the DID spec. 4. European e-Passports A European e-passport relies on a set of international standards to prove its authenticity and integrity using cryptographic techniques. These standards work together to ensure the data on the passport is both verifiable and resistant to tampering or cloning. These passports contain cryptographic material used to verify the legitimacy of the passport, thereby delegating the authority of the identity represented to the bearer\u2014assuming basic checks are met (e.g., does the bearer match the photo?). 4.1 ICAO Doc 9303 The foundational specification for Machine Readable Travel Documents (MRTDs). It defines: The structure and contents of the e-passport chip. Cryptographic protocols such as: Passive Authentication (PA): Verifies the integrity and authenticity of the stored data using digital signatures from the issuing authority. Active Authentication (AA): Ensures the chip hasn\u2019t been cloned by using a private key challenge/response protocol. 4.2 ISO/IEC 7816 (Parts 4, 8, 9) Standards for electronic identification cards with contacts, adapted for contactless chips in e-passports: Part 4: File system structure and command set (APDUs). Part 8: Security-related functions including authentication. Part 9: Access control and secure messaging. These standards allow secure and standardized access to the data groups (DG1\u2013DG15) on the chip. 4.3 ISO/IEC 14443 (Parts 1\u20134) Defines the physical and communication characteristics for contactless smartcards: Enables NFC communication between passport chips and readers. Standard across all ICAO-compliant e-passports. 4.4 ISO/IEC 7501-1 Specifies the physical format and layout of machine-readable passports, including: Dimensions Data placement The Machine Readable Zone (MRZ), which is used to derive keys for secure access (e.g., Basic Access Control). 4.5 CSCA and DSC Certificates Each country operates a Country Signing Certificate Authority (CSCA) and issues Document Signer Certificates ( DSCs) : The CSCA\u2019s public key is distributed globally. The DSC signs the data on each passport. Verifiers use the CSCA chain to validate the DSC signature and ensure the data\u2019s authenticity. Together, these standards form the cryptographic backbone that allows e-passports to be trusted across borders. 5. UCAN - User Controlled Authorization Networks To align with Web3 standards, SSIMPL has adopted UCAN. UCAN challenges the traditional client-server model, shifting control to the client. Clients generate their own JWTs, specifying the request and resource they intend to access. Each JWT is signed with the user\u2019s private key, allowing the server to verify the signature and determine whether access should be granted. This essentially reverses the OAuth 2.0 flow, where clients request a server-issued JWT with specific scopes. It should be noted that UCAN was originally designed for \"delegated authorization\". Meaning, an issuer creates a token that allows the bearer of the token to perform certain actions on certain resources. For authentication, an addition is required. 5.1 Delegated signing using UCAN By creating a dedicated, short-lived and identity-bound token (by setting receivers' DID as the audience of the token), a user can delegate signing authority towards another entity, like the website they are currently on. The UCAN token is then embedded in the signature JWT in the prf-array. This is relevant if the user is adding content to the website and the website wants to have this content bound to a DID. The implications are that all content on the internet HAS to be tied to an author, producer, etc. Which means that fraudulent content, like non-consensual, AI-generated media, will have to signed as well. 6. Cryptography Achieving true decentralization requires users to handle complex cryptographic operations. To make this accessible, all cryptographic functionality should be encapsulated within a user-friendly interface \u2014 a \u2018wallet\u2019. This wallet contains at least one cryptographic keypair: A root AES key for encrypting and decrypting the user\u2019s data. An EC-based public/private key pair for signing and verifying data. These algorithms are widely recognized standards, so I won\u2019t delve into their inner workings\u2014Wikipedia is your friend for that. With these keys, users can encrypt, decrypt, sign, and verify data entirely on the client side, ensuring full control over their information. In the subscription system, an additional key pair is introduced. This keypair facilitates sharing a derived AES key\u2014not the root AES key, but a deterministically generated AES key unique to each subscription. 6.1 Post-Quantum disclaimer With the inevitable advent of quantum computing, these algorithms will change eventually. Currently, there are several candidates which could potentially take over the aforementioned algorithms. SSIMPL will adopt them as soon as they are ripe. The biggest concern lies in asymmetric encryption, which is used for signing and sharing of secrets. Through Shor's algorithm, the asymmetric encryption algorithms we currently rely on will be cracked, meaning that private keys can be derived based on public keys. This is why everything related to asymmetric encryption should have an expiration time. The other concern is in the symmetric encryption, for which exclusively AES is used. SSIMPL is already post-quantum proof in this area, since it used AES-256. Which is overkill in the current day and time, but will be equivalent to AES-128 when quantum computing becomes more prevalent. 7. Multibase Encoding On the internet, a lot of raw data (bytes) is transported using something called base encoding. These encodings essentially turn the raw bytes into a piece of transportable and near-readable text. But when you wish to access the raw bytes again on the receiving side, you need to know which encoding was used in order to decode it. But there are a lot of different encodings to choose from. This means that encoding and decoding must be well-documented. With Multibase encoding, a special reserved character for each specific encoding is appended to the encoded value which indicates which encoding was used. This means that anyone receiving the encoded bytes can always decode it. More can be read here . 9. Notary server In order to keep the SSIMPL network trustworthy, certain open-source checkpoints have to be available which can verify someone's root claims purely based on cryptography. These servers are stateless in essence, but it needs to check the ledger to see if a DID hasn't been invalidated yet. For this reason, a supporter of the SSIMPL network is allowed to combine both functionalities","title":"Concepts"},{"location":"concepts/#concepts","text":"","title":"Concepts"},{"location":"concepts/#1-bip","text":"BIP stands for Bitcoin Improvement Proposal \u2014 it\u2019s a formal design document used to propose changes or additions to Bitcoin\u2019s protocol, processes, or tools. It\u2019s essentially the \u201cRFC\u201d (Request for Comments) system for Bitcoin. Each BIP has: A number (e.g., BIP-39) A type (Standards Track, Informational, or Process) A status (Draft, Proposed, Final, etc.) A detailed specification of the proposed change. For example: BIP-32 defines hierarchical deterministic (HD) wallets. BIP-39 defines mnemonic phrases (seed words). BIP-44 defines a multi-account wallet structure. While SSIMPL has nothing to do with Bitcoin, or even blockchains, it does rely upon some of the same concepts.","title":"1. BIP"},{"location":"concepts/#11-bip32","text":"BIP32 (Bitcoin Improvement Proposal 32) defines Hierarchical Deterministic (HD) wallets, which allow you to derive a tree of key pairs from a single root seed. Key features: One backup = all keys: Backing up the seed gives access to all derived keys. Key separation: You can derive independent identities (child keys) without compromising the master. Public derivation: Given a parent public key, you can derive child public keys (but not private keys). Hardened derivation: A safer variant where child keys can\u2019t be derived from public keys, but requires the parent private key. How it works: You start with a single seed (often from a BIP39 mnemonic). From that seed, it deterministically derives a master keypair (private + public key). Then you can derive child key pairs from the master, and children of those, forming a tree structure.","title":"1.1 BIP32"},{"location":"concepts/#12-bip39","text":"BIP39 (Bitcoin Improvement Proposal 39) defines a way to represent a deterministic wallet\u2019s private key using a human-readable set of words, called a mnemonic phrase. Key properties: Mnemonic = backup: If you lose your device, you can recover your entire wallet using the phrase. Language-agnostic: Wordlists exist for multiple languages. Deterministic: The same phrase will always regenerate the same wallet. How it works: First, a cryptographically strong random number (entropy) is generated. Then that number is converted into a sequence of 12\u201324 words chosen from a predefined list of 2048 words. Finally, this phrase can be used to derive a seed, which in turn can generate a hierarchy of keys (e.g., via BIP32).","title":"1.2 BIP39"},{"location":"concepts/#2-self-sovereign-identity","text":"Self-Sovereign Identity (SSI) is a Decentralised identity model where individuals control their own digital identities without relying on central authorities. The main issue which the concept SSI usually tends to ignore is 'truth'. As long an individual is in complete control of their own digital identity, who is to say this individual is not impersonating some other individual, or worse, conjuring up a completely new non-existing identity. Cryptography can verify who issued a claim and whether it was tampered with, but it cannot verify the truthfulness of the claim itself. The validity of claims like a name, nationality, or birthdate ultimately depends on who the issuer is and whether they are trusted. However, since this requires authorities to be fully aligned with Web3 standards, we hit a dead end. Currently, most (if not all) authorities don't have any way to issue a DID . So what SSIMPL does, is reversing the flow yet again: an individual can create their own DID along with the related cryptographic keys. Which is actually in line with the entire idea of decentralisation. But 'claims' an individual makes are divided into 2 categories: formal and informal.","title":"2. Self-Sovereign-Identity"},{"location":"concepts/#21-informal-claims","text":"Informal claims can be made within certain scopes, where the user provides their own data along with their signature. By nature, these claims cannot be verified by an authority. However, other identities can attest to a claim by signing it, effectively endorsing its validity. This attestation carries moral responsibility, as the signer\u2019s DID and signature become publicly associated with the claim.","title":"2.1 Informal Claims"},{"location":"concepts/#22-formal-claims","text":"Formal claims cannot be self-issued; they must come from a recognized authority. At this point in time, the only formal claims available to a SSIMPL user, are the ones coming from their passport. These can be used to chain other claims of course. For example: by taking your full name and birthdate, you can match then with the names and birthdate written on an official diploma.","title":"2.2 Formal Claims"},{"location":"concepts/#3-did","text":"Decentralised IDentifier. A DID is a globally unique identifier that is not controlled by a central authority. Unlike traditional identifiers (usernames, emails, etc.), a DID is linked to a cryptographic keypair, allowing users to prove ownership without relying on a centralised system. A DID follows this format: did:<method>:<identifier> In SSIMPL, primarily the 'key' method is used. This means that each 'identifier' part is actually the public part of a specific cryptographic public/private keypair. Each user is responsible for their own private key, which is used to sign data. The public key can always be used to verify the signature. The only small deviation from the spec is that SSIMPL promotes the use of Multibase encoding , which means that even the public key part of the DID is multibase-encoded. The 'key' method also means there is no real need for a DID document, which is part of the DID spec.","title":"3. DID"},{"location":"concepts/#4-european-e-passports","text":"A European e-passport relies on a set of international standards to prove its authenticity and integrity using cryptographic techniques. These standards work together to ensure the data on the passport is both verifiable and resistant to tampering or cloning. These passports contain cryptographic material used to verify the legitimacy of the passport, thereby delegating the authority of the identity represented to the bearer\u2014assuming basic checks are met (e.g., does the bearer match the photo?).","title":"4. European e-Passports"},{"location":"concepts/#41-icao-doc-9303","text":"The foundational specification for Machine Readable Travel Documents (MRTDs). It defines: The structure and contents of the e-passport chip. Cryptographic protocols such as: Passive Authentication (PA): Verifies the integrity and authenticity of the stored data using digital signatures from the issuing authority. Active Authentication (AA): Ensures the chip hasn\u2019t been cloned by using a private key challenge/response protocol.","title":"4.1 ICAO Doc 9303"},{"location":"concepts/#42-isoiec-7816-parts-4-8-9","text":"Standards for electronic identification cards with contacts, adapted for contactless chips in e-passports: Part 4: File system structure and command set (APDUs). Part 8: Security-related functions including authentication. Part 9: Access control and secure messaging. These standards allow secure and standardized access to the data groups (DG1\u2013DG15) on the chip.","title":"4.2 ISO/IEC 7816 (Parts 4, 8, 9)"},{"location":"concepts/#43-isoiec-14443-parts-14","text":"Defines the physical and communication characteristics for contactless smartcards: Enables NFC communication between passport chips and readers. Standard across all ICAO-compliant e-passports.","title":"4.3 ISO/IEC 14443 (Parts 1\u20134)"},{"location":"concepts/#44-isoiec-7501-1","text":"Specifies the physical format and layout of machine-readable passports, including: Dimensions Data placement The Machine Readable Zone (MRZ), which is used to derive keys for secure access (e.g., Basic Access Control).","title":"4.4 ISO/IEC 7501-1"},{"location":"concepts/#45-csca-and-dsc-certificates","text":"Each country operates a Country Signing Certificate Authority (CSCA) and issues Document Signer Certificates ( DSCs) : The CSCA\u2019s public key is distributed globally. The DSC signs the data on each passport. Verifiers use the CSCA chain to validate the DSC signature and ensure the data\u2019s authenticity. Together, these standards form the cryptographic backbone that allows e-passports to be trusted across borders.","title":"4.5 CSCA and DSC Certificates"},{"location":"concepts/#5-ucan-user-controlled-authorization-networks","text":"To align with Web3 standards, SSIMPL has adopted UCAN. UCAN challenges the traditional client-server model, shifting control to the client. Clients generate their own JWTs, specifying the request and resource they intend to access. Each JWT is signed with the user\u2019s private key, allowing the server to verify the signature and determine whether access should be granted. This essentially reverses the OAuth 2.0 flow, where clients request a server-issued JWT with specific scopes. It should be noted that UCAN was originally designed for \"delegated authorization\". Meaning, an issuer creates a token that allows the bearer of the token to perform certain actions on certain resources. For authentication, an addition is required.","title":"5. UCAN - User Controlled Authorization Networks"},{"location":"concepts/#51-delegated-signing-using-ucan","text":"By creating a dedicated, short-lived and identity-bound token (by setting receivers' DID as the audience of the token), a user can delegate signing authority towards another entity, like the website they are currently on. The UCAN token is then embedded in the signature JWT in the prf-array. This is relevant if the user is adding content to the website and the website wants to have this content bound to a DID. The implications are that all content on the internet HAS to be tied to an author, producer, etc. Which means that fraudulent content, like non-consensual, AI-generated media, will have to signed as well.","title":"5.1 Delegated signing using UCAN"},{"location":"concepts/#6-cryptography","text":"Achieving true decentralization requires users to handle complex cryptographic operations. To make this accessible, all cryptographic functionality should be encapsulated within a user-friendly interface \u2014 a \u2018wallet\u2019. This wallet contains at least one cryptographic keypair: A root AES key for encrypting and decrypting the user\u2019s data. An EC-based public/private key pair for signing and verifying data. These algorithms are widely recognized standards, so I won\u2019t delve into their inner workings\u2014Wikipedia is your friend for that. With these keys, users can encrypt, decrypt, sign, and verify data entirely on the client side, ensuring full control over their information. In the subscription system, an additional key pair is introduced. This keypair facilitates sharing a derived AES key\u2014not the root AES key, but a deterministically generated AES key unique to each subscription.","title":"6. Cryptography"},{"location":"concepts/#61-post-quantum-disclaimer","text":"With the inevitable advent of quantum computing, these algorithms will change eventually. Currently, there are several candidates which could potentially take over the aforementioned algorithms. SSIMPL will adopt them as soon as they are ripe. The biggest concern lies in asymmetric encryption, which is used for signing and sharing of secrets. Through Shor's algorithm, the asymmetric encryption algorithms we currently rely on will be cracked, meaning that private keys can be derived based on public keys. This is why everything related to asymmetric encryption should have an expiration time. The other concern is in the symmetric encryption, for which exclusively AES is used. SSIMPL is already post-quantum proof in this area, since it used AES-256. Which is overkill in the current day and time, but will be equivalent to AES-128 when quantum computing becomes more prevalent.","title":"6.1 Post-Quantum disclaimer"},{"location":"concepts/#7-multibase-encoding","text":"On the internet, a lot of raw data (bytes) is transported using something called base encoding. These encodings essentially turn the raw bytes into a piece of transportable and near-readable text. But when you wish to access the raw bytes again on the receiving side, you need to know which encoding was used in order to decode it. But there are a lot of different encodings to choose from. This means that encoding and decoding must be well-documented. With Multibase encoding, a special reserved character for each specific encoding is appended to the encoded value which indicates which encoding was used. This means that anyone receiving the encoded bytes can always decode it. More can be read here .","title":"7. Multibase Encoding"},{"location":"concepts/#9-notary-server","text":"In order to keep the SSIMPL network trustworthy, certain open-source checkpoints have to be available which can verify someone's root claims purely based on cryptography. These servers are stateless in essence, but it needs to check the ledger to see if a DID hasn't been invalidated yet. For this reason, a supporter of the SSIMPL network is allowed to combine both functionalities","title":"9. Notary server"},{"location":"concepts/authority-in-decentralised-systems/","text":"Authorities in Decentralised Identity Systems It might seem counter-intuitive, why would there be a need for a trusted centralised party in a Decentralised identity system? This is simply because identity is non-deterministic. It is a social construct that is solely based on trust. At birth, you have to trust that your parents/guardians take care to perform the correct steps to register you. During your life you have to trust the authorities to take care of this identity, especially in the area of security. Given an ever-changing world (consider the digital revolution), this is a huge undertaking. In a Decentralised identity system, everybody is equal, as is their ability to make claims about themselves. By introducing a central authority, everybody can agree that their judgment is the correct one.","title":"Authorities in Decentralised Identity Systems"},{"location":"concepts/authority-in-decentralised-systems/#authorities-in-decentralised-identity-systems","text":"It might seem counter-intuitive, why would there be a need for a trusted centralised party in a Decentralised identity system? This is simply because identity is non-deterministic. It is a social construct that is solely based on trust. At birth, you have to trust that your parents/guardians take care to perform the correct steps to register you. During your life you have to trust the authorities to take care of this identity, especially in the area of security. Given an ever-changing world (consider the digital revolution), this is a huge undertaking. In a Decentralised identity system, everybody is equal, as is their ability to make claims about themselves. By introducing a central authority, everybody can agree that their judgment is the correct one.","title":"Authorities in Decentralised Identity Systems"},{"location":"concepts/bip32/","text":"BIP32 BIP32 (Bitcoin Improvement Proposal 32) defines Hierarchical Deterministic (HD) wallets, which allow you to derive a tree of key pairs from a single root seed. How it works: Starts with a single seed (often from a BIP39 mnemonic). From that seed, it deterministically derives a master keypair (private + public key). You can derive child key pairs from the master, and children of those, forming a tree structure. Key features: One backup = all keys: Backing up the seed gives access to all derived keys. Key separation: You can derive independent identities (child keys) without compromising the master. Public derivation: Given a parent public key, you can derive child public keys (but not private keys). Hardened derivation: A safer variant where child keys can\u2019t be derived from public keys, but requires the parent private key.","title":"BIP32"},{"location":"concepts/bip32/#bip32","text":"BIP32 (Bitcoin Improvement Proposal 32) defines Hierarchical Deterministic (HD) wallets, which allow you to derive a tree of key pairs from a single root seed. How it works: Starts with a single seed (often from a BIP39 mnemonic). From that seed, it deterministically derives a master keypair (private + public key). You can derive child key pairs from the master, and children of those, forming a tree structure. Key features: One backup = all keys: Backing up the seed gives access to all derived keys. Key separation: You can derive independent identities (child keys) without compromising the master. Public derivation: Given a parent public key, you can derive child public keys (but not private keys). Hardened derivation: A safer variant where child keys can\u2019t be derived from public keys, but requires the parent private key.","title":"BIP32"},{"location":"concepts/bip39/","text":"BIP39 BIP39 (Bitcoin Improvement Proposal 39) defines a way to represent a deterministic wallet\u2019s private key using a human-readable set of words, called a mnemonic phrase. How it works: A cryptographically strong random number (entropy) is generated. That number is converted into a sequence of 12\u201324 words chosen from a predefined list of 2048 words. This phrase can be used to derive a seed, which in turn can generate a hierarchy of keys (e.g., via BIP32). Key properties: Mnemonic = backup: If you lose your device, you can recover your entire wallet using the phrase. Language-agnostic: Wordlists exist for multiple languages. Deterministic: The same phrase will always regenerate the same wallet.","title":"BIP39"},{"location":"concepts/bip39/#bip39","text":"BIP39 (Bitcoin Improvement Proposal 39) defines a way to represent a deterministic wallet\u2019s private key using a human-readable set of words, called a mnemonic phrase. How it works: A cryptographically strong random number (entropy) is generated. That number is converted into a sequence of 12\u201324 words chosen from a predefined list of 2048 words. This phrase can be used to derive a seed, which in turn can generate a hierarchy of keys (e.g., via BIP32). Key properties: Mnemonic = backup: If you lose your device, you can recover your entire wallet using the phrase. Language-agnostic: Wordlists exist for multiple languages. Deterministic: The same phrase will always regenerate the same wallet.","title":"BIP39"},{"location":"concepts/cryptography/","text":"Cryptography Achieving true decentralization requires users to handle complex cryptographic operations. To make this accessible, all cryptographic functionality should be encapsulated within a user-friendly interface \u2014 a \u2018wallet\u2019. This wallet contains at least one cryptographic keypair: A root AES key for encrypting and decrypting the user\u2019s data. An EC-based public/private key pair for signing and verifying data. These algorithms are widely recognized standards, so I won\u2019t delve into their inner workings\u2014Wikipedia is your friend for that. With these keys, users can encrypt, decrypt, sign, and verify data entirely on the client side, ensuring full control over their information. In the subscription system, an additional key pair is introduced. This keypair facilitates sharing a derived AES key\u2014not the root AES key, but a deterministically generated AES key unique to each subscription. Post-Quantum disclaimer With the inevitable advent of quantum computing, these algorithms will change eventually. Currently, there are several candidates which could potentially take over the aforementioned algorithms. DoaToa will adapt accordingly. The biggest concern lies in asymmetric encryption, which is used for signing and sharing of secrets. Through Shor's algorithm, the asymmetric encryption algorithms we currently rely on will be cracked, meaning that private keys can be derived based on public keys. This is why everything related to asymmetric encryption should have an expiration time. And this is also part of the design of DoaToa: most data stays client-side.","title":"Cryptography"},{"location":"concepts/cryptography/#cryptography","text":"Achieving true decentralization requires users to handle complex cryptographic operations. To make this accessible, all cryptographic functionality should be encapsulated within a user-friendly interface \u2014 a \u2018wallet\u2019. This wallet contains at least one cryptographic keypair: A root AES key for encrypting and decrypting the user\u2019s data. An EC-based public/private key pair for signing and verifying data. These algorithms are widely recognized standards, so I won\u2019t delve into their inner workings\u2014Wikipedia is your friend for that. With these keys, users can encrypt, decrypt, sign, and verify data entirely on the client side, ensuring full control over their information. In the subscription system, an additional key pair is introduced. This keypair facilitates sharing a derived AES key\u2014not the root AES key, but a deterministically generated AES key unique to each subscription.","title":"Cryptography"},{"location":"concepts/cryptography/#post-quantum-disclaimer","text":"With the inevitable advent of quantum computing, these algorithms will change eventually. Currently, there are several candidates which could potentially take over the aforementioned algorithms. DoaToa will adapt accordingly. The biggest concern lies in asymmetric encryption, which is used for signing and sharing of secrets. Through Shor's algorithm, the asymmetric encryption algorithms we currently rely on will be cracked, meaning that private keys can be derived based on public keys. This is why everything related to asymmetric encryption should have an expiration time. And this is also part of the design of DoaToa: most data stays client-side.","title":"Post-Quantum disclaimer"},{"location":"concepts/did/","text":"DID Decentralised IDentifier. A DID is a globally unique identifier that is not controlled by a central authority. Unlike traditional identifiers (usernames, emails, etc.), a DID is linked to a cryptographic keypair, allowing users to prove ownership without relying on a centralised system. A DID follows this format: did:<method>:<identifier> In DoaToa, primarily the 'key' method is used. This means that each 'identifier' part is actually the public part of a specific cryptographic public/private keypair. Each user is responsible for their own private key, which is used to sign data. The public key can always be used to verify the signature. The 'key' method also means there is no real need for a DID document, which is part of the DID spec.","title":"DID"},{"location":"concepts/did/#did","text":"Decentralised IDentifier. A DID is a globally unique identifier that is not controlled by a central authority. Unlike traditional identifiers (usernames, emails, etc.), a DID is linked to a cryptographic keypair, allowing users to prove ownership without relying on a centralised system. A DID follows this format: did:<method>:<identifier> In DoaToa, primarily the 'key' method is used. This means that each 'identifier' part is actually the public part of a specific cryptographic public/private keypair. Each user is responsible for their own private key, which is used to sign data. The public key can always be used to verify the signature. The 'key' method also means there is no real need for a DID document, which is part of the DID spec.","title":"DID"},{"location":"concepts/ipfs/","text":"IPFS IPFS (InterPlanetary File System) is a peer-to-peer distributed file system that aims to make the web more * Decentralised , resilient , and permanent *. Decentralised Storage Traditionally, large tech companies have been responsible for storing data. This centralised model comes with several drawbacks, including single points of failure, high costs, and control over access to information. Decentralised storage offers an alternative by distributing data across multiple nodes instead of relying on a central server. This approach provides several advantages: Eliminates Single Points of Failure \u2013 No central server means no single point of failure, reducing the risk of data loss or downtime. Censorship Resistance \u2013 Data isn\u2019t controlled by a single entity, making it harder for governments or organizations to censor or remove information. Improved Availability \u2013 Multiple copies of data are stored across a network, ensuring accessibility even if some nodes go offline. Lower Costs \u2013 Users can share and utilize spare storage from others, reducing infrastructure costs compared to traditional cloud providers. Tamper Resistance \u2013 Cryptographic hashing and content addressing ensure data integrity and prevent unauthorized modifications. Trustless Environment \u2013 No need to rely on a central authority; cryptographic verification ensures data is stored and retrieved correctly. Decentralised Storage in DoaToa For DoaToa, a peer-to-peer approach aligns best with its principles. The InterPlanetary File System (IPFS) is a Decentralised, peer-to-peer protocol for storing and sharing data. Unlike traditional location-based addressing (where URLs point to specific servers), IPFS uses content addressing, identifying files by their cryptographic hash (CID). Key Features of IPFS: Content Addressing \u2013 Files are identified by unique hashes, ensuring integrity and deduplication. Peer-to-Peer Distribution \u2013 Files are retrieved from multiple nodes rather than a central server. Versioning \u2013 IPFS can track changes, similar to Git. Caching \u2013 Popular content is cached across the network for faster access. Interoperability \u2013 Works well with blockchain and Decentralised applications (dApps). Problems IPFS Solves: Redundancy & Availability \u2013 Data remains accessible without reliance on a single server. Censorship Resistance \u2013 Information remains online as long as at least one node hosts it. Efficient Content Delivery \u2013 Data is retrieved from the nearest available node, reducing latency. However, IPFS alone does not guarantee permanent storage\u2014data can disappear if no node continues to host it. To ensure persistence, data must be pinned. This can be done either manually (free) or through a pinning service. Currently, DoaToa uses a pinning service. The ultimate way to do it, would be to support self-hosting and pinning from the wallet itself, ensuring full control over data storage. However, since the wallet resides on a phone, a phone is managed by their OS and most OS-es are quite strict about persistent connections (and rightly so), this setup is not feasible. Key Features Content-addressed: Files are identified by their cryptographic hash , not by location (like a URL). Distributed storage: Files are shared and stored across a network of peers. Versioned: Supports version control and immutable data structures (like Git). Offline-friendly: Data can be accessed locally without needing a central server. How It Works A file is added to IPFS and broken into chunks. Each chunk is hashed and stored in a Merkle DAG . The root hash (CID - Content Identifier) acts as the address for the entire file. Anyone with the CID can fetch the file from any peer who has it. Common Use Cases Decentralised websites (often with IPNS or ENS) Content archiving and permanence Peer-to-peer file sharing Blockchain data storage (e.g., NFTs) IPFS is often used with pinning services or local nodes to ensure data availability.","title":"IPFS"},{"location":"concepts/ipfs/#ipfs","text":"IPFS (InterPlanetary File System) is a peer-to-peer distributed file system that aims to make the web more * Decentralised , resilient , and permanent *.","title":"IPFS"},{"location":"concepts/ipfs/#decentralised-storage","text":"Traditionally, large tech companies have been responsible for storing data. This centralised model comes with several drawbacks, including single points of failure, high costs, and control over access to information. Decentralised storage offers an alternative by distributing data across multiple nodes instead of relying on a central server. This approach provides several advantages: Eliminates Single Points of Failure \u2013 No central server means no single point of failure, reducing the risk of data loss or downtime. Censorship Resistance \u2013 Data isn\u2019t controlled by a single entity, making it harder for governments or organizations to censor or remove information. Improved Availability \u2013 Multiple copies of data are stored across a network, ensuring accessibility even if some nodes go offline. Lower Costs \u2013 Users can share and utilize spare storage from others, reducing infrastructure costs compared to traditional cloud providers. Tamper Resistance \u2013 Cryptographic hashing and content addressing ensure data integrity and prevent unauthorized modifications. Trustless Environment \u2013 No need to rely on a central authority; cryptographic verification ensures data is stored and retrieved correctly.","title":"Decentralised Storage"},{"location":"concepts/ipfs/#decentralised-storage-in-doatoa","text":"For DoaToa, a peer-to-peer approach aligns best with its principles. The InterPlanetary File System (IPFS) is a Decentralised, peer-to-peer protocol for storing and sharing data. Unlike traditional location-based addressing (where URLs point to specific servers), IPFS uses content addressing, identifying files by their cryptographic hash (CID).","title":"Decentralised Storage in DoaToa"},{"location":"concepts/ipfs/#key-features-of-ipfs","text":"Content Addressing \u2013 Files are identified by unique hashes, ensuring integrity and deduplication. Peer-to-Peer Distribution \u2013 Files are retrieved from multiple nodes rather than a central server. Versioning \u2013 IPFS can track changes, similar to Git. Caching \u2013 Popular content is cached across the network for faster access. Interoperability \u2013 Works well with blockchain and Decentralised applications (dApps).","title":"Key Features of IPFS:"},{"location":"concepts/ipfs/#problems-ipfs-solves","text":"Redundancy & Availability \u2013 Data remains accessible without reliance on a single server. Censorship Resistance \u2013 Information remains online as long as at least one node hosts it. Efficient Content Delivery \u2013 Data is retrieved from the nearest available node, reducing latency. However, IPFS alone does not guarantee permanent storage\u2014data can disappear if no node continues to host it. To ensure persistence, data must be pinned. This can be done either manually (free) or through a pinning service. Currently, DoaToa uses a pinning service. The ultimate way to do it, would be to support self-hosting and pinning from the wallet itself, ensuring full control over data storage. However, since the wallet resides on a phone, a phone is managed by their OS and most OS-es are quite strict about persistent connections (and rightly so), this setup is not feasible.","title":"Problems IPFS Solves:"},{"location":"concepts/ipfs/#key-features","text":"Content-addressed: Files are identified by their cryptographic hash , not by location (like a URL). Distributed storage: Files are shared and stored across a network of peers. Versioned: Supports version control and immutable data structures (like Git). Offline-friendly: Data can be accessed locally without needing a central server.","title":"Key Features"},{"location":"concepts/ipfs/#how-it-works","text":"A file is added to IPFS and broken into chunks. Each chunk is hashed and stored in a Merkle DAG . The root hash (CID - Content Identifier) acts as the address for the entire file. Anyone with the CID can fetch the file from any peer who has it.","title":"How It Works"},{"location":"concepts/ipfs/#common-use-cases","text":"Decentralised websites (often with IPNS or ENS) Content archiving and permanence Peer-to-peer file sharing Blockchain data storage (e.g., NFTs) IPFS is often used with pinning services or local nodes to ensure data availability.","title":"Common Use Cases"},{"location":"concepts/multibase-encoding/","text":"Multibase Encoding On the internet, a lot of raw data (bytes) is transported using something called base encoding. These encodings essentially turn the raw bytes into a piece of transportable and near-readable text. But when you wish to access the raw bytes again on the receiving side, you need to know which encoding was used in order to decode it. But there are a lot of different encodings to choose from. This means that encoding and decoding must be well-documented. With Multibase encoding, a special reserved character for each specific encoding is appended to the encoded value which indicates which encoding was used. This means that anyone receiving the encoded bytes can always decode it. More can be read here .","title":"Multibase Encoding"},{"location":"concepts/multibase-encoding/#multibase-encoding","text":"On the internet, a lot of raw data (bytes) is transported using something called base encoding. These encodings essentially turn the raw bytes into a piece of transportable and near-readable text. But when you wish to access the raw bytes again on the receiving side, you need to know which encoding was used in order to decode it. But there are a lot of different encodings to choose from. This means that encoding and decoding must be well-documented. With Multibase encoding, a special reserved character for each specific encoding is appended to the encoded value which indicates which encoding was used. This means that anyone receiving the encoded bytes can always decode it. More can be read here .","title":"Multibase Encoding"},{"location":"concepts/self-sovereign-identity/","text":"Self-Sovereign-Identity Self-Sovereign Identity (SSI) is a Decentralised identity model where individuals control their own digital identities without relying on central authorities. The main issue which the concept SSI usually tends to ignore is 'truth'. As long an individual is in complete control of their own digital identity, who is to say this individual is not impersonating some other individual, or worse, conjuring up a completely new non-existing one. Cryptography can verify who issued a claim and whether it was tampered with, but it cannot verify the truthfulness of the claim itself. The validity of claims like a name, nationality, or birthdate ultimately depends on who the issuer is and whether they are trusted. However, since this requires authorities to be fully aligned with Web3 standards, we hit a dead end. Currently, most (if not all) authorities don't have any way to issue DIDs. So what DoaToa does, is reversing the flow yet again: an individual can create their own DID along with the related cryptographic keys. Which is actually in line with the entire idea of decentralisation. But 'claims' an individual makes are divided into 2 categories: formal and informal. Informal Claims Informal claims can be made within certain scopes, where the user provides their own data along with their signature. By nature, these claims cannot be verified by an authority. However, other identities can attest to a claim by signing it, effectively endorsing its validity. This attestation carries moral responsibility, as the signer\u2019s DID and signature become publicly associated with the claim. Formal Claims Formal claims cannot be self-issued; they must come from a recognized authority. At this point in time, the only formal claims available to a DoaToa user, are the ones coming from their passport. These can be used to chain other claims of course: by taking your full name and birthdate, you can match then with the names and birthdate written on an official diploma. This functionality is out of scope for now.","title":"Self-Sovereign-Identity"},{"location":"concepts/self-sovereign-identity/#self-sovereign-identity","text":"Self-Sovereign Identity (SSI) is a Decentralised identity model where individuals control their own digital identities without relying on central authorities. The main issue which the concept SSI usually tends to ignore is 'truth'. As long an individual is in complete control of their own digital identity, who is to say this individual is not impersonating some other individual, or worse, conjuring up a completely new non-existing one. Cryptography can verify who issued a claim and whether it was tampered with, but it cannot verify the truthfulness of the claim itself. The validity of claims like a name, nationality, or birthdate ultimately depends on who the issuer is and whether they are trusted. However, since this requires authorities to be fully aligned with Web3 standards, we hit a dead end. Currently, most (if not all) authorities don't have any way to issue DIDs. So what DoaToa does, is reversing the flow yet again: an individual can create their own DID along with the related cryptographic keys. Which is actually in line with the entire idea of decentralisation. But 'claims' an individual makes are divided into 2 categories: formal and informal.","title":"Self-Sovereign-Identity"},{"location":"concepts/self-sovereign-identity/#informal-claims","text":"Informal claims can be made within certain scopes, where the user provides their own data along with their signature. By nature, these claims cannot be verified by an authority. However, other identities can attest to a claim by signing it, effectively endorsing its validity. This attestation carries moral responsibility, as the signer\u2019s DID and signature become publicly associated with the claim.","title":"Informal Claims"},{"location":"concepts/self-sovereign-identity/#formal-claims","text":"Formal claims cannot be self-issued; they must come from a recognized authority. At this point in time, the only formal claims available to a DoaToa user, are the ones coming from their passport. These can be used to chain other claims of course: by taking your full name and birthdate, you can match then with the names and birthdate written on an official diploma. This functionality is out of scope for now.","title":"Formal Claims"},{"location":"concepts/standardised-e-passports/","text":"Cryptographic Standards Enabling European e-Passport Integrity A European e-passport relies on a set of international standards to prove its authenticity and integrity using cryptographic techniques. These standards work together to ensure the data on the passport is both verifiable and resistant to tampering or cloning. ICAO Doc 9303 The foundational specification for Machine Readable Travel Documents (MRTDs). It defines: The structure and contents of the e-passport chip. Cryptographic protocols such as: Passive Authentication (PA): Verifies the integrity and authenticity of the stored data using digital signatures from the issuing authority. Active Authentication (AA): Ensures the chip hasn\u2019t been cloned by using a private key challenge/response protocol. ISO/IEC 7816 (Parts 4, 8, 9) Standards for electronic identification cards with contacts, adapted for contactless chips in e-passports: Part 4: File system structure and command set (APDUs). Part 8: Security-related functions including authentication. Part 9: Access control and secure messaging. These standards allow secure and standardized access to the data groups (DG1\u2013DG15) on the chip. ISO/IEC 14443 (Parts 1\u20134) Defines the physical and communication characteristics for contactless smartcards: Enables NFC communication between passport chips and readers. Standard across all ICAO-compliant e-passports. ISO/IEC 7501-1 Specifies the physical format and layout of machine-readable passports, including: Dimensions Data placement The Machine Readable Zone (MRZ), which is used to derive keys for secure access (e.g., Basic Access Control). CSCA and DSC Certificates Each country operates a Country Signing Certificate Authority (CSCA) and issues Document Signer Certificates ( DSCs) : The CSCA\u2019s public key is distributed globally. The DSC signs the data on each passport. Verifiers use the CSCA chain to validate the DSC signature and ensure the data\u2019s authenticity. Together, these standards form the cryptographic backbone that allows e-passports to be trusted across borders.","title":"Cryptographic Standards Enabling European e-Passport Integrity"},{"location":"concepts/standardised-e-passports/#cryptographic-standards-enabling-european-e-passport-integrity","text":"A European e-passport relies on a set of international standards to prove its authenticity and integrity using cryptographic techniques. These standards work together to ensure the data on the passport is both verifiable and resistant to tampering or cloning.","title":"Cryptographic Standards Enabling European e-Passport Integrity"},{"location":"concepts/standardised-e-passports/#icao-doc-9303","text":"The foundational specification for Machine Readable Travel Documents (MRTDs). It defines: The structure and contents of the e-passport chip. Cryptographic protocols such as: Passive Authentication (PA): Verifies the integrity and authenticity of the stored data using digital signatures from the issuing authority. Active Authentication (AA): Ensures the chip hasn\u2019t been cloned by using a private key challenge/response protocol.","title":"ICAO Doc 9303"},{"location":"concepts/standardised-e-passports/#isoiec-7816-parts-4-8-9","text":"Standards for electronic identification cards with contacts, adapted for contactless chips in e-passports: Part 4: File system structure and command set (APDUs). Part 8: Security-related functions including authentication. Part 9: Access control and secure messaging. These standards allow secure and standardized access to the data groups (DG1\u2013DG15) on the chip.","title":"ISO/IEC 7816 (Parts 4, 8, 9)"},{"location":"concepts/standardised-e-passports/#isoiec-14443-parts-14","text":"Defines the physical and communication characteristics for contactless smartcards: Enables NFC communication between passport chips and readers. Standard across all ICAO-compliant e-passports.","title":"ISO/IEC 14443 (Parts 1\u20134)"},{"location":"concepts/standardised-e-passports/#isoiec-7501-1","text":"Specifies the physical format and layout of machine-readable passports, including: Dimensions Data placement The Machine Readable Zone (MRZ), which is used to derive keys for secure access (e.g., Basic Access Control).","title":"ISO/IEC 7501-1"},{"location":"concepts/standardised-e-passports/#csca-and-dsc-certificates","text":"Each country operates a Country Signing Certificate Authority (CSCA) and issues Document Signer Certificates ( DSCs) : The CSCA\u2019s public key is distributed globally. The DSC signs the data on each passport. Verifiers use the CSCA chain to validate the DSC signature and ensure the data\u2019s authenticity. Together, these standards form the cryptographic backbone that allows e-passports to be trusted across borders.","title":"CSCA and DSC Certificates"},{"location":"concepts/ucan/","text":"UCAN - User Controlled Authorization Networks To align with Web3 standards, DoaToa has adopted UCAN. UCAN challenges the traditional client-server model, shifting control to the client. Clients generate their own JWTs, specifying the request and resource they intend to access. Each JWT is signed with the user\u2019s private key, allowing the server to verify the signature and determine whether access should be granted. This essentially reverses the OAuth 2.0 flow, where clients request a server-issued JWT with specific scopes. It should be noted that UCAN was originally designed for \"delegated authorization\". Meaning, an issuer creates a token that allows the bearer of the token to perform certain actions on certain resources. For authentication, an addition is required. 'UCAN Connect' Like Open ID Connect adds an identification layer to OAuth2, UCAN Connect also adds an identification layer to UCAN. By embedding (verified) claims within UCAN JWTs, authentication systems eliminate the need to store user data, further decentralizing trust. The receiver of the token notifies the issuer of the token which scope(s) they would like to receive, and the issuer adds the related claims to the token. The receiver also should specify where the JWT should be sent. Implementation of the UCAN Connect flow So how would all of this work in a real-world example? Let's set up a scenario. We start with three parties: Party A. The owner of the identity, aka the issuer of the UCAN token. Party B. The id-wallet of the owner (like DoaToa). Party C. A website, let's say a webshop called \"foo-bar.baz\". Party D. The server of \"foo-bar.baz\". Pre-requisite: both Party A/B, and Party C/D have a DID, signed by DoaToa. For a non-natural person, this means a DID from someone inside the legal entity, willing to represent the legal entity. Typically, A will visit C, which at some point requires A to identify themselves (to complete an order, for example). Party C has to create a scannable image (like a QR-code), which provides Party B all necessary information to authenticate Party A: The DID of Party C. The scopes of Party A that Party C requires. A connection proposal. Containing either a channel id - used to set up a WebRTC channel, or an authentication endpoint (Party D) - to which the token should be sent. This payload MUST be a multibase-encoded JSON message: { \"requestor\": \"did:key:a1b2c3d4e5f6g7h8ij9k0\", \"scopes\": [ \"did\", \"private-address\" ], \"destination\": { \"channelId\": \"someId\", \"authenticationEndpoint\": \"someEndpoint\" } } Authentication through WebRTC Party D SHOULD initiate the WebRTC connection using the specified channel id. Party C is also allowed to do so, but that would expose the UCAN token to Party C, which is less secure. Party B will do so some seconds after scanning the payload. After the connection is set up, Party B will send the UCAN Connect token. Afterward, the connection is closed. Authentication through an endpoint The Party D connection endpoint MUST have the same domain as that of Party C. A subdomain is allowed. The connection endpoint MUST be as follows: ```http request POST /ucan-connect/auth HTTP/2 Authorization: \"Bearer ${theUCANConnectToken}\" (no body should be provided) ``` This endpoint MUST respond with either a 200 OK or a 401 UNAUTHENTICATED 200 OK: the tokens' signature matches the provided DID 401 UNAUTHENTICATED: the tokens' signature does not match the provided DID. The DID will be in the 'claims' array of the UCAN token. Or the DID does not match the specified public key. Then Party D SHOULD provide Party C with another token, specific for the current context, so Party C doesn't need to know anything about Party A. Delegated signing using UCAN By creating a dedicated, short-lived and identity-bound token (by setting receivers' DID as the audience of the token), a user can delegate signing authority towards another entity, like the website they are currently on. The UCAN token is then embedded in the signature JWT in the prf-array. This is relevant if the user is adding content to the website and the website wants to have this content bound to a DID. The implications are that all content on the internet HAS to be tied to an author, producer, etc. Which means that fraudulent content, like non-consensual, AI-generated media, will have to signed as well.","title":"UCAN - User Controlled Authorization Networks"},{"location":"concepts/ucan/#ucan-user-controlled-authorization-networks","text":"To align with Web3 standards, DoaToa has adopted UCAN. UCAN challenges the traditional client-server model, shifting control to the client. Clients generate their own JWTs, specifying the request and resource they intend to access. Each JWT is signed with the user\u2019s private key, allowing the server to verify the signature and determine whether access should be granted. This essentially reverses the OAuth 2.0 flow, where clients request a server-issued JWT with specific scopes. It should be noted that UCAN was originally designed for \"delegated authorization\". Meaning, an issuer creates a token that allows the bearer of the token to perform certain actions on certain resources. For authentication, an addition is required.","title":"UCAN - User Controlled Authorization Networks"},{"location":"concepts/ucan/#ucan-connect","text":"Like Open ID Connect adds an identification layer to OAuth2, UCAN Connect also adds an identification layer to UCAN. By embedding (verified) claims within UCAN JWTs, authentication systems eliminate the need to store user data, further decentralizing trust. The receiver of the token notifies the issuer of the token which scope(s) they would like to receive, and the issuer adds the related claims to the token. The receiver also should specify where the JWT should be sent.","title":"'UCAN Connect'"},{"location":"concepts/ucan/#implementation-of-the-ucan-connect-flow","text":"So how would all of this work in a real-world example? Let's set up a scenario. We start with three parties: Party A. The owner of the identity, aka the issuer of the UCAN token. Party B. The id-wallet of the owner (like DoaToa). Party C. A website, let's say a webshop called \"foo-bar.baz\". Party D. The server of \"foo-bar.baz\". Pre-requisite: both Party A/B, and Party C/D have a DID, signed by DoaToa. For a non-natural person, this means a DID from someone inside the legal entity, willing to represent the legal entity. Typically, A will visit C, which at some point requires A to identify themselves (to complete an order, for example). Party C has to create a scannable image (like a QR-code), which provides Party B all necessary information to authenticate Party A: The DID of Party C. The scopes of Party A that Party C requires. A connection proposal. Containing either a channel id - used to set up a WebRTC channel, or an authentication endpoint (Party D) - to which the token should be sent. This payload MUST be a multibase-encoded JSON message: { \"requestor\": \"did:key:a1b2c3d4e5f6g7h8ij9k0\", \"scopes\": [ \"did\", \"private-address\" ], \"destination\": { \"channelId\": \"someId\", \"authenticationEndpoint\": \"someEndpoint\" } }","title":"Implementation of the UCAN Connect flow"},{"location":"concepts/ucan/#authentication-through-webrtc","text":"Party D SHOULD initiate the WebRTC connection using the specified channel id. Party C is also allowed to do so, but that would expose the UCAN token to Party C, which is less secure. Party B will do so some seconds after scanning the payload. After the connection is set up, Party B will send the UCAN Connect token. Afterward, the connection is closed.","title":"Authentication through WebRTC"},{"location":"concepts/ucan/#authentication-through-an-endpoint","text":"The Party D connection endpoint MUST have the same domain as that of Party C. A subdomain is allowed. The connection endpoint MUST be as follows: ```http request POST /ucan-connect/auth HTTP/2 Authorization: \"Bearer ${theUCANConnectToken}\" (no body should be provided) ``` This endpoint MUST respond with either a 200 OK or a 401 UNAUTHENTICATED 200 OK: the tokens' signature matches the provided DID 401 UNAUTHENTICATED: the tokens' signature does not match the provided DID. The DID will be in the 'claims' array of the UCAN token. Or the DID does not match the specified public key. Then Party D SHOULD provide Party C with another token, specific for the current context, so Party C doesn't need to know anything about Party A.","title":"Authentication through an endpoint"},{"location":"concepts/ucan/#delegated-signing-using-ucan","text":"By creating a dedicated, short-lived and identity-bound token (by setting receivers' DID as the audience of the token), a user can delegate signing authority towards another entity, like the website they are currently on. The UCAN token is then embedded in the signature JWT in the prf-array. This is relevant if the user is adding content to the website and the website wants to have this content bound to a DID. The implications are that all content on the internet HAS to be tied to an author, producer, etc. Which means that fraudulent content, like non-consensual, AI-generated media, will have to signed as well.","title":"Delegated signing using UCAN"},{"location":"concepts/web-rtc/","text":"WebRTC WebRTC (Web Real-Time Communication) is an open-source project and API standard that enables peer-to-peer communication directly between browsers or mobile apps, without requiring intermediate servers for media routing. Key Features Real-time audio and video streaming. Data channels for arbitrary peer-to-peer data transfer. Low latency , ideal for voice/video calls, gaming, and file sharing. How It Works Signaling (out of scope for the WebRTC-spec): Exchanging connection info (e.g., IPs, codecs) between peers using a separate method (like WebSocket). ICE (Interactive Connectivity Establishment): Finds the best path through NATs/firewalls. DTLS/SRTP: Ensures encryption and secure transport . STUN/TURN servers: Help peers connect when direct connections are blocked. Common Use Cases Video conferencing Voice calls Screen sharing Real-time multiplayer games Decentralised applications WebRTC is supported by all major browsers and is a core building block for modern real-time web applications.","title":"WebRTC"},{"location":"concepts/web-rtc/#webrtc","text":"WebRTC (Web Real-Time Communication) is an open-source project and API standard that enables peer-to-peer communication directly between browsers or mobile apps, without requiring intermediate servers for media routing.","title":"WebRTC"},{"location":"concepts/web-rtc/#key-features","text":"Real-time audio and video streaming. Data channels for arbitrary peer-to-peer data transfer. Low latency , ideal for voice/video calls, gaming, and file sharing.","title":"Key Features"},{"location":"concepts/web-rtc/#how-it-works","text":"Signaling (out of scope for the WebRTC-spec): Exchanging connection info (e.g., IPs, codecs) between peers using a separate method (like WebSocket). ICE (Interactive Connectivity Establishment): Finds the best path through NATs/firewalls. DTLS/SRTP: Ensures encryption and secure transport . STUN/TURN servers: Help peers connect when direct connections are blocked.","title":"How It Works"},{"location":"concepts/web-rtc/#common-use-cases","text":"Video conferencing Voice calls Screen sharing Real-time multiplayer games Decentralised applications WebRTC is supported by all major browsers and is a core building block for modern real-time web applications.","title":"Common Use Cases"}]}